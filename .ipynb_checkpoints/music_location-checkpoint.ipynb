{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0033de1b-72c1-457b-b04e-702b4e4eed7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting folium\n",
      "  Using cached folium-0.19.5-py2.py3-none-any.whl (110 kB)\n",
      "Collecting torch\n",
      "  Using cached torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.9.1)\n",
      "Collecting keras_tuner\n",
      "  Using cached keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from folium) (2.32.2)\n",
      "Requirement already satisfied: jinja2>=2.9 in /opt/conda/lib/python3.10/site-packages (from folium) (3.1.2)\n",
      "Requirement already satisfied: xyzservices in /opt/conda/lib/python3.10/site-packages (from folium) (2023.2.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from folium) (1.23.5)\n",
      "Collecting branca>=0.6.0\n",
      "  Using cached branca-0.8.1-py3-none-any.whl (26 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.11.0)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Collecting sympy==1.13.1\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Collecting triton==3.2.0\n",
      "  Using cached triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2\n",
      "  Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2023.3.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (67.6.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.64.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.12)\n",
      "Collecting kt-legacy\n",
      "  Using cached kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.9->folium) (2.1.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->folium) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->folium) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->folium) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->folium) (1.26.15)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
      "Installing collected packages: triton, nvidia-cusparselt-cu12, kt-legacy, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, keras_tuner, branca, nvidia-cusolver-cu12, folium, torch\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.11.1\n",
      "    Uninstalling sympy-1.11.1:\n",
      "      Successfully uninstalled sympy-1.11.1\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.39\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.39:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.39\n",
      "Successfully installed branca-0.8.1 filelock-3.18.0 folium-0.19.5 keras_tuner-1.4.7 kt-legacy-1.0.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.6.0 triton-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install folium torch pandas scikit-learn tensorflow keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ea9931-f123-45b4-b7a4-484269966d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"data/all_data.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b3db015-224b-4655-af9d-686463a5c4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id_number</th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MFCC1</th>\n",
       "      <th>MFCC2</th>\n",
       "      <th>MFCC3</th>\n",
       "      <th>MFCC4</th>\n",
       "      <th>...</th>\n",
       "      <th>Tonnetz2</th>\n",
       "      <th>Tonnetz3</th>\n",
       "      <th>Tonnetz4</th>\n",
       "      <th>Tonnetz5</th>\n",
       "      <th>Tonnetz6</th>\n",
       "      <th>RMS</th>\n",
       "      <th>SpectralRolloff</th>\n",
       "      <th>ZeroCrossingRate</th>\n",
       "      <th>Length</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Saoko</td>\n",
       "      <td>Rosalía</td>\n",
       "      <td>Spain</td>\n",
       "      <td>40.42</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>-87.781052</td>\n",
       "      <td>110.309486</td>\n",
       "      <td>-8.193514</td>\n",
       "      <td>12.189231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031682</td>\n",
       "      <td>0.031099</td>\n",
       "      <td>0.049473</td>\n",
       "      <td>0.010867</td>\n",
       "      <td>-0.011590</td>\n",
       "      <td>0.226229</td>\n",
       "      <td>4086.001064</td>\n",
       "      <td>0.095356</td>\n",
       "      <td>140.202132</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>LA FAMA</td>\n",
       "      <td>Rosalía</td>\n",
       "      <td>Spain</td>\n",
       "      <td>40.42</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>-142.864670</td>\n",
       "      <td>129.827835</td>\n",
       "      <td>5.117205</td>\n",
       "      <td>23.859261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126945</td>\n",
       "      <td>0.053468</td>\n",
       "      <td>0.035345</td>\n",
       "      <td>-0.006220</td>\n",
       "      <td>0.009974</td>\n",
       "      <td>0.271468</td>\n",
       "      <td>2803.446239</td>\n",
       "      <td>0.059665</td>\n",
       "      <td>251.379274</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spanish Caravan</td>\n",
       "      <td>The Doors</td>\n",
       "      <td>United States</td>\n",
       "      <td>38.88</td>\n",
       "      <td>-77.00</td>\n",
       "      <td>-208.096588</td>\n",
       "      <td>98.872444</td>\n",
       "      <td>-13.651766</td>\n",
       "      <td>36.340504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067584</td>\n",
       "      <td>0.138996</td>\n",
       "      <td>0.009897</td>\n",
       "      <td>-0.000284</td>\n",
       "      <td>0.004213</td>\n",
       "      <td>0.059760</td>\n",
       "      <td>4195.064707</td>\n",
       "      <td>0.097843</td>\n",
       "      <td>178.306667</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>MALAMENTE - Cap.1: Augurio</td>\n",
       "      <td>Rosalía</td>\n",
       "      <td>Spain</td>\n",
       "      <td>40.42</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>-144.406586</td>\n",
       "      <td>103.702049</td>\n",
       "      <td>5.672822</td>\n",
       "      <td>21.341652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103094</td>\n",
       "      <td>0.069495</td>\n",
       "      <td>0.033981</td>\n",
       "      <td>-0.015257</td>\n",
       "      <td>0.012077</td>\n",
       "      <td>0.243367</td>\n",
       "      <td>3184.956769</td>\n",
       "      <td>0.052307</td>\n",
       "      <td>168.085351</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Chicken Teriyaki</td>\n",
       "      <td>Rosalía</td>\n",
       "      <td>Spain</td>\n",
       "      <td>40.42</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>-137.848801</td>\n",
       "      <td>85.967781</td>\n",
       "      <td>3.030798</td>\n",
       "      <td>22.190674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015080</td>\n",
       "      <td>-0.024649</td>\n",
       "      <td>-0.018667</td>\n",
       "      <td>0.015736</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>0.261582</td>\n",
       "      <td>4304.387237</td>\n",
       "      <td>0.071205</td>\n",
       "      <td>133.886304</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id_number                  track_name artist_name        Country   \n",
       "0                1                       Saoko     Rosalía          Spain  \\\n",
       "1                2                     LA FAMA     Rosalía          Spain   \n",
       "2                3             Spanish Caravan   The Doors  United States   \n",
       "3                4  MALAMENTE - Cap.1: Augurio     Rosalía          Spain   \n",
       "4                5            Chicken Teriyaki     Rosalía          Spain   \n",
       "\n",
       "   Latitude  Longitude       MFCC1       MFCC2      MFCC3      MFCC4  ...   \n",
       "0     40.42      -3.75  -87.781052  110.309486  -8.193514  12.189231  ...  \\\n",
       "1     40.42      -3.75 -142.864670  129.827835   5.117205  23.859261  ...   \n",
       "2     38.88     -77.00 -208.096588   98.872444 -13.651766  36.340504  ...   \n",
       "3     40.42      -3.75 -144.406586  103.702049   5.672822  21.341652  ...   \n",
       "4     40.42      -3.75 -137.848801   85.967781   3.030798  22.190674  ...   \n",
       "\n",
       "   Tonnetz2  Tonnetz3  Tonnetz4  Tonnetz5  Tonnetz6       RMS   \n",
       "0  0.031682  0.031099  0.049473  0.010867 -0.011590  0.226229  \\\n",
       "1  0.126945  0.053468  0.035345 -0.006220  0.009974  0.271468   \n",
       "2 -0.067584  0.138996  0.009897 -0.000284  0.004213  0.059760   \n",
       "3  0.103094  0.069495  0.033981 -0.015257  0.012077  0.243367   \n",
       "4  0.015080 -0.024649 -0.018667  0.015736 -0.007838  0.261582   \n",
       "\n",
       "   SpectralRolloff  ZeroCrossingRate      Length  Language  \n",
       "0      4086.001064          0.095356  140.202132        es  \n",
       "1      2803.446239          0.059665  251.379274        es  \n",
       "2      4195.064707          0.097843  178.306667        en  \n",
       "3      3184.956769          0.052307  168.085351        es  \n",
       "4      4304.387237          0.071205  133.886304        es  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the unneeded columns\n",
    "df = df.drop(columns=['location', 'track_id', 'listeners', 'genre', 'Capital'])\n",
    "\n",
    "# Display the updated DataFrame to verify the removal\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1181429b-2d0f-4dfe-ac59-913210ed8cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 22:31:56.970021: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "df['Language'] = df['Language'].astype(str)\n",
    "\n",
    "\n",
    "# Tokenize language column\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['Language'])\n",
    "\n",
    "# Convert languages to integer sequences\n",
    "df['language_encoded'] = tokenizer.texts_to_sequences(df['Language'])\n",
    "\n",
    "# Since language is a single word, each sequence is a single number\n",
    "df['language_encoded'] = df['language_encoded'].apply(lambda x: x[0] if x else 0)\n",
    "\n",
    "# Convert to NumPy array for training\n",
    "import numpy as np\n",
    "X_language = np.array(df['language_encoded']).reshape(-1, 1)\n",
    "df.drop(columns=['Language'], inplace=True)  # Remove the original Language column\n",
    "df.rename(columns={'language_encoded': 'Language'}, inplace=True)  # Rename encoded column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "274649ce-99c3-4c9a-99c0-fae7d730ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "df['Country'] = df['Country'].astype(str)\n",
    "\n",
    "\n",
    "# Tokenize country column\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['Country'])\n",
    "\n",
    "# Convert countries to integer sequences\n",
    "df['country_encoded'] = tokenizer.texts_to_sequences(df['Country'])\n",
    "\n",
    "# Since country is a single word, each sequence is a single number\n",
    "df['country_encoded'] = df['country_encoded'].apply(lambda x: x[0] if x else 0)\n",
    "\n",
    "# Convert to NumPy array for training\n",
    "import numpy as np\n",
    "X_language = np.array(df['country_encoded']).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a633d5d-d9d0-4191-af86-3ec649ce6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Count occurrences of each class\n",
    "class_counts = df['country_encoded'].value_counts()\n",
    "\n",
    "# Filter out classes that appear only once\n",
    "df = df[df['country_encoded'].isin(class_counts[class_counts > 5].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49daa09a-f4b0-4690-a488-943d2ff64cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id_number</th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MFCC1</th>\n",
       "      <th>MFCC2</th>\n",
       "      <th>MFCC3</th>\n",
       "      <th>MFCC4</th>\n",
       "      <th>...</th>\n",
       "      <th>Tonnetz3</th>\n",
       "      <th>Tonnetz4</th>\n",
       "      <th>Tonnetz5</th>\n",
       "      <th>Tonnetz6</th>\n",
       "      <th>RMS</th>\n",
       "      <th>SpectralRolloff</th>\n",
       "      <th>ZeroCrossingRate</th>\n",
       "      <th>Length</th>\n",
       "      <th>Language</th>\n",
       "      <th>country_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Saoko</td>\n",
       "      <td>Rosalía</td>\n",
       "      <td>Spain</td>\n",
       "      <td>40.42</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>-87.781052</td>\n",
       "      <td>110.309486</td>\n",
       "      <td>-8.193514</td>\n",
       "      <td>12.189231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031099</td>\n",
       "      <td>0.049473</td>\n",
       "      <td>0.010867</td>\n",
       "      <td>-0.011590</td>\n",
       "      <td>0.226229</td>\n",
       "      <td>4086.001064</td>\n",
       "      <td>0.095356</td>\n",
       "      <td>140.202132</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>LA FAMA</td>\n",
       "      <td>Rosalía</td>\n",
       "      <td>Spain</td>\n",
       "      <td>40.42</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>-142.864670</td>\n",
       "      <td>129.827835</td>\n",
       "      <td>5.117205</td>\n",
       "      <td>23.859261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053468</td>\n",
       "      <td>0.035345</td>\n",
       "      <td>-0.006220</td>\n",
       "      <td>0.009974</td>\n",
       "      <td>0.271468</td>\n",
       "      <td>2803.446239</td>\n",
       "      <td>0.059665</td>\n",
       "      <td>251.379274</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spanish Caravan</td>\n",
       "      <td>The Doors</td>\n",
       "      <td>United States</td>\n",
       "      <td>38.88</td>\n",
       "      <td>-77.00</td>\n",
       "      <td>-208.096588</td>\n",
       "      <td>98.872444</td>\n",
       "      <td>-13.651766</td>\n",
       "      <td>36.340504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138996</td>\n",
       "      <td>0.009897</td>\n",
       "      <td>-0.000284</td>\n",
       "      <td>0.004213</td>\n",
       "      <td>0.059760</td>\n",
       "      <td>4195.064707</td>\n",
       "      <td>0.097843</td>\n",
       "      <td>178.306667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>MALAMENTE - Cap.1: Augurio</td>\n",
       "      <td>Rosalía</td>\n",
       "      <td>Spain</td>\n",
       "      <td>40.42</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>-144.406586</td>\n",
       "      <td>103.702049</td>\n",
       "      <td>5.672822</td>\n",
       "      <td>21.341652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069495</td>\n",
       "      <td>0.033981</td>\n",
       "      <td>-0.015257</td>\n",
       "      <td>0.012077</td>\n",
       "      <td>0.243367</td>\n",
       "      <td>3184.956769</td>\n",
       "      <td>0.052307</td>\n",
       "      <td>168.085351</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Chicken Teriyaki</td>\n",
       "      <td>Rosalía</td>\n",
       "      <td>Spain</td>\n",
       "      <td>40.42</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>-137.848801</td>\n",
       "      <td>85.967781</td>\n",
       "      <td>3.030798</td>\n",
       "      <td>22.190674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024649</td>\n",
       "      <td>-0.018667</td>\n",
       "      <td>0.015736</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>0.261582</td>\n",
       "      <td>4304.387237</td>\n",
       "      <td>0.071205</td>\n",
       "      <td>133.886304</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5126</th>\n",
       "      <td>5223</td>\n",
       "      <td>God Of War</td>\n",
       "      <td>Ari Koivunen</td>\n",
       "      <td>Finland</td>\n",
       "      <td>60.25</td>\n",
       "      <td>25.05</td>\n",
       "      <td>30.474360</td>\n",
       "      <td>87.008713</td>\n",
       "      <td>-15.577330</td>\n",
       "      <td>20.209152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001803</td>\n",
       "      <td>-0.044276</td>\n",
       "      <td>-0.004870</td>\n",
       "      <td>-0.007030</td>\n",
       "      <td>0.336402</td>\n",
       "      <td>5221.879487</td>\n",
       "      <td>0.122226</td>\n",
       "      <td>237.986667</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5127</th>\n",
       "      <td>5224</td>\n",
       "      <td>End Of Love</td>\n",
       "      <td>Anna Abreu</td>\n",
       "      <td>Finland</td>\n",
       "      <td>60.25</td>\n",
       "      <td>25.05</td>\n",
       "      <td>-138.658005</td>\n",
       "      <td>83.150330</td>\n",
       "      <td>0.411348</td>\n",
       "      <td>16.266539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098265</td>\n",
       "      <td>0.044978</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>-0.020714</td>\n",
       "      <td>0.133496</td>\n",
       "      <td>5142.373954</td>\n",
       "      <td>0.099743</td>\n",
       "      <td>229.320317</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5129</th>\n",
       "      <td>5226</td>\n",
       "      <td>Forever</td>\n",
       "      <td>Sturm und Drang</td>\n",
       "      <td>Finland</td>\n",
       "      <td>60.25</td>\n",
       "      <td>25.05</td>\n",
       "      <td>38.631622</td>\n",
       "      <td>63.954712</td>\n",
       "      <td>-0.771039</td>\n",
       "      <td>32.017376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005176</td>\n",
       "      <td>0.024704</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.028819</td>\n",
       "      <td>0.338810</td>\n",
       "      <td>6135.716178</td>\n",
       "      <td>0.141349</td>\n",
       "      <td>198.298458</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5130</th>\n",
       "      <td>5227</td>\n",
       "      <td>Todii</td>\n",
       "      <td>Oliver Mtukudzi</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>-17.72</td>\n",
       "      <td>31.03</td>\n",
       "      <td>-95.678047</td>\n",
       "      <td>129.015182</td>\n",
       "      <td>9.116899</td>\n",
       "      <td>26.797274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056516</td>\n",
       "      <td>-0.011660</td>\n",
       "      <td>-0.005137</td>\n",
       "      <td>-0.013422</td>\n",
       "      <td>0.274915</td>\n",
       "      <td>3168.206764</td>\n",
       "      <td>0.056786</td>\n",
       "      <td>314.212472</td>\n",
       "      <td>8</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5131</th>\n",
       "      <td>5228</td>\n",
       "      <td>Slave</td>\n",
       "      <td>Lucky Dube</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>-25.73</td>\n",
       "      <td>28.20</td>\n",
       "      <td>-175.813843</td>\n",
       "      <td>83.501564</td>\n",
       "      <td>0.180811</td>\n",
       "      <td>16.100397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035308</td>\n",
       "      <td>-0.035332</td>\n",
       "      <td>-0.003700</td>\n",
       "      <td>-0.006308</td>\n",
       "      <td>0.060070</td>\n",
       "      <td>5511.576205</td>\n",
       "      <td>0.122501</td>\n",
       "      <td>264.928118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4969 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      track_id_number                  track_name      artist_name   \n",
       "0                   1                       Saoko          Rosalía  \\\n",
       "1                   2                     LA FAMA          Rosalía   \n",
       "2                   3             Spanish Caravan        The Doors   \n",
       "3                   4  MALAMENTE - Cap.1: Augurio          Rosalía   \n",
       "4                   5            Chicken Teriyaki          Rosalía   \n",
       "...               ...                         ...              ...   \n",
       "5126             5223                  God Of War     Ari Koivunen   \n",
       "5127             5224                 End Of Love       Anna Abreu   \n",
       "5129             5226                     Forever  Sturm und Drang   \n",
       "5130             5227                       Todii  Oliver Mtukudzi   \n",
       "5131             5228                       Slave       Lucky Dube   \n",
       "\n",
       "            Country  Latitude  Longitude       MFCC1       MFCC2      MFCC3   \n",
       "0             Spain     40.42      -3.75  -87.781052  110.309486  -8.193514  \\\n",
       "1             Spain     40.42      -3.75 -142.864670  129.827835   5.117205   \n",
       "2     United States     38.88     -77.00 -208.096588   98.872444 -13.651766   \n",
       "3             Spain     40.42      -3.75 -144.406586  103.702049   5.672822   \n",
       "4             Spain     40.42      -3.75 -137.848801   85.967781   3.030798   \n",
       "...             ...       ...        ...         ...         ...        ...   \n",
       "5126        Finland     60.25      25.05   30.474360   87.008713 -15.577330   \n",
       "5127        Finland     60.25      25.05 -138.658005   83.150330   0.411348   \n",
       "5129        Finland     60.25      25.05   38.631622   63.954712  -0.771039   \n",
       "5130       Zimbabwe    -17.72      31.03  -95.678047  129.015182   9.116899   \n",
       "5131   South Africa    -25.73      28.20 -175.813843   83.501564   0.180811   \n",
       "\n",
       "          MFCC4  ...  Tonnetz3  Tonnetz4  Tonnetz5  Tonnetz6       RMS   \n",
       "0     12.189231  ...  0.031099  0.049473  0.010867 -0.011590  0.226229  \\\n",
       "1     23.859261  ...  0.053468  0.035345 -0.006220  0.009974  0.271468   \n",
       "2     36.340504  ...  0.138996  0.009897 -0.000284  0.004213  0.059760   \n",
       "3     21.341652  ...  0.069495  0.033981 -0.015257  0.012077  0.243367   \n",
       "4     22.190674  ... -0.024649 -0.018667  0.015736 -0.007838  0.261582   \n",
       "...         ...  ...       ...       ...       ...       ...       ...   \n",
       "5126  20.209152  ... -0.001803 -0.044276 -0.004870 -0.007030  0.336402   \n",
       "5127  16.266539  ...  0.098265  0.044978  0.026042 -0.020714  0.133496   \n",
       "5129  32.017376  ...  0.005176  0.024704  0.001183  0.028819  0.338810   \n",
       "5130  26.797274  ...  0.056516 -0.011660 -0.005137 -0.013422  0.274915   \n",
       "5131  16.100397  ... -0.035308 -0.035332 -0.003700 -0.006308  0.060070   \n",
       "\n",
       "      SpectralRolloff  ZeroCrossingRate      Length  Language  country_encoded  \n",
       "0         4086.001064          0.095356  140.202132         2                8  \n",
       "1         2803.446239          0.059665  251.379274         2                8  \n",
       "2         4195.064707          0.097843  178.306667         1                1  \n",
       "3         3184.956769          0.052307  168.085351         2                8  \n",
       "4         4304.387237          0.071205  133.886304         2                8  \n",
       "...               ...               ...         ...       ...              ...  \n",
       "5126      5221.879487          0.122226  237.986667         1               25  \n",
       "5127      5142.373954          0.099743  229.320317         1               25  \n",
       "5129      6135.716178          0.141349  198.298458         1               25  \n",
       "5130      3168.206764          0.056786  314.212472         8              145  \n",
       "5131      5511.576205          0.122501  264.928118         1                2  \n",
       "\n",
       "[4969 rows x 57 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90cf4406-6a02-448d-aa0f-d3718c48ce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97/635989508.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[mfcc_cols + chroma_cols + spectral_cols + tonnetz_cols + independent_cols] = scaler.fit_transform(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select feature columns\n",
    "mfcc_cols = [f'MFCC{i+1}' for i in range(20)]\n",
    "chroma_cols = [f'Chroma{i+1}' for i in range(12)]\n",
    "spectral_cols = [f'SpectralContrast{i+1}' for i in range(7)]\n",
    "tonnetz_cols = [f'Tonnetz{i+1}' for i in range(6)]\n",
    "independent_cols = ['RMS', 'SpectralRolloff', 'ZeroCrossingRate', 'Length', 'Language']\n",
    "\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "df[mfcc_cols + chroma_cols + spectral_cols + tonnetz_cols + independent_cols] = scaler.fit_transform(\n",
    "    df[mfcc_cols + chroma_cols + spectral_cols + tonnetz_cols + independent_cols]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70b33f9f-7ee8-4cf1-a2eb-a84490c43406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_seq = df[mfcc_cols + chroma_cols + spectral_cols + tonnetz_cols].values\n",
    "X_nonseq = df[independent_cols].values\n",
    "y = df['country_encoded'].values\n",
    "\n",
    "X_seq_train, X_seq_test, X_nonseq_train, X_nonseq_test, y_train, y_test = train_test_split(\n",
    "    X_seq, X_nonseq, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5f9d050-99ac-4740-9bac-8dd532bac169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_seq_train shape: (3975, 45)\n",
      "X_nonseq_train shape: (3975, 5)\n",
      "y_train shape: (3975,)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_nonseq_train shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_nonseq_train\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Expected: (samples, features)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_train shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_train\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Expected: (samples,)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mnum_classes\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_classes' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"X_seq_train shape:\", X_seq_train.shape)  # Expected: (samples, timesteps, 1)\n",
    "print(\"X_nonseq_train shape:\", X_nonseq_train.shape)  # Expected: (samples, features)\n",
    "print(\"y_train shape:\", y_train.shape)  # Expected: (samples,)\n",
    "print(\"Number of classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db0cb3fb-1786-4fa3-9e01-5b5bf06dc18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X_seq_train and X_seq_test to (num_samples, timesteps, num_features)\n",
    "X_seq_train = X_seq_train.reshape((X_seq_train.shape[0], 1, X_seq_train.shape[1]))\n",
    "X_seq_test = X_seq_test.reshape((X_seq_test.shape[0], 1, X_seq_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a552123-c3e4-4880-9af5-c4ec3013c033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 3s 8ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      " 19/125 [===>..........................] - ETA: 0s - loss: nan - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_seq_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_nonseq_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_seq_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_nonseq_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\n\u001b[1;32m     32\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate\n",
    "\n",
    "# Define input shapes\n",
    "seq_input_shape = X_seq_train.shape[1:]  # (time_steps, features) for LSTM\n",
    "nonseq_input_shape = (X_nonseq_train.shape[1],)  # (features,) for Dense\n",
    "\n",
    "# LSTM branch\n",
    "seq_input = Input(shape=seq_input_shape, name=\"seq_input\")\n",
    "x_seq = LSTM(64, return_sequences=True)(seq_input)\n",
    "x_seq = LSTM(32)(x_seq)  # Reducing to a single vector\n",
    "\n",
    "# Dense branch\n",
    "nonseq_input = Input(shape=nonseq_input_shape, name=\"nonseq_input\")\n",
    "x_nonseq = Dense(32, activation=\"relu\")(nonseq_input)\n",
    "x_nonseq = Dense(16, activation=\"relu\")(x_nonseq)\n",
    "\n",
    "# Concatenate both feature representations\n",
    "merged = Concatenate()([x_seq, x_nonseq])\n",
    "output = Dense(len(set(y)), activation=\"softmax\") (merged)  # Multi-class classification\n",
    "\n",
    "# Define and compile the model\n",
    "model = Model(inputs=[seq_input, nonseq_input], outputs=output)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    [X_seq_train, X_nonseq_train], y_train,\n",
    "    validation_data=([X_seq_test, X_nonseq_test], y_test),\n",
    "    epochs=20, batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fe100f7-479c-4767-ad50-916b994fa601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 16) dtype=float32 (created by layer 'tf.__operators__.getitem_1')>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e413334-43f2-4c1e-976e-61b1c123ddf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_seq_train before reshape: (3975, 1, 45)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_seq_train before reshape:\", X_seq_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e43128e6-bde9-4fb9-9166-845c6d4f02fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the model as a function so that Keras Tuner can search over hyperparameters\n",
    "def build_model(hp):\n",
    "    # Sequential input (for sequence data)\n",
    "    seq_input = Input(shape=(X_seq_train.shape[1], 1), name=\"seq_input\")\n",
    "    \n",
    "    # LSTM layer with hyperparameter tuning\n",
    "    x_seq = LSTM(\n",
    "        units=hp.Int('lstm_units', min_value=32, max_value=128, step=32), \n",
    "        return_sequences=False\n",
    "    )(seq_input)\n",
    "    \n",
    "    # Dropout rate tuning\n",
    "    x_seq = Dropout(rate=hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1))(x_seq)\n",
    "    \n",
    "    # Non-sequential input (for non-sequential data)\n",
    "    nonseq_input = Input(shape=(X_nonseq_train.shape[1],), name=\"nonseq_input\")\n",
    "    \n",
    "    # Concatenate the sequence and non-sequence data\n",
    "    x = Concatenate()([x_seq, nonseq_input])\n",
    "    \n",
    "    # Dense layers with hyperparameter tuning\n",
    "    x = Dense(units=hp.Int('dense_units', min_value=64, max_value=256, step=64), activation='relu')(x)\n",
    "    x = Dropout(rate=hp.Float('dropout_rate_dense', min_value=0.2, max_value=0.5, step=0.1))(x)\n",
    "    x = Dense(units=hp.Int('dense_units2', min_value=32, max_value=128, step=32), activation='relu')(x)\n",
    "    \n",
    "    # Output layer for classification\n",
    "    output = Dense(len(set(y)), activation='softmax')(x)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Model(inputs=[seq_input, nonseq_input], outputs=output)\n",
    "    \n",
    "    # Compile the model with hyperparameter tuning for the learning rate\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='LOG')),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90fbe9ec-318d-40f7-b0b6-c898e4b8594d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from kt_tuner/lstm_finetuning/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    build_model,  # The model-building function\n",
    "    objective='val_accuracy',  # Objective to maximize\n",
    "    max_epochs=50,  # Max epochs per trial\n",
    "    factor=3,  # Reduces the number of trials after each round\n",
    "    directory='kt_tuner',  # Directory to store the results\n",
    "    project_name='lstm_finetuning'  # Name of the project\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8752c75f-06c6-48eb-966d-8461bf9f02d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 Complete [00h 00m 01s]\n",
      "\n",
      "Best val_accuracy So Far: 0.0\n",
      "Total elapsed time: 00h 13m 56s\n",
      "\n",
      "Search: Running Trial #8\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "128               |64                |lstm_units\n",
      "0.4               |0.3               |dropout_rate\n",
      "256               |128               |dense_units\n",
      "0.2               |0.4               |dropout_rate_dense\n",
      "128               |32                |dense_units2\n",
      "0.0040901         |1.7009e-05        |learning_rate\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "3                 |3                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='seq_input'), name='seq_input', description=\"created by layer 'seq_input'\"), but it was called on an input with incompatible shape (None, 1, 45).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/src/tuners/hyperband.py\", line 427, in run_trial\n",
      "    return super().run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/tmp/__autograph_generated_filent90i4eu.py\", line 15, in tf__train_function\n",
      "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 889, in train_step\n",
      "        y_pred = self(x, training=True)\n",
      "    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
      "        raise e.with_traceback(filtered_tb) from None\n",
      "    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n",
      "        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n",
      "\n",
      "    ValueError: Exception encountered when calling layer \"model\" (type Functional).\n",
      "    \n",
      "    Input 0 of layer \"lstm\" is incompatible with the layer: expected shape=(None, None, 1), found shape=(None, 1, 45)\n",
      "    \n",
      "    Call arguments received by layer \"model\" (type Functional):\n",
      "      • inputs=('tf.Tensor(shape=(None, 1, 45), dtype=float32)', 'tf.Tensor(shape=(None, 5), dtype=float32)')\n",
      "      • training=True\n",
      "      • mask=None\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/src/tuners/hyperband.py\", line 427, in run_trial\n    return super().run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/tmp/__autograph_generated_filent90i4eu.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Exception encountered when calling layer \"model\" (type Functional).\n    \n    Input 0 of layer \"lstm\" is incompatible with the layer: expected shape=(None, None, 1), found shape=(None, 1, 45)\n    \n    Call arguments received by layer \"model\" (type Functional):\n      • inputs=('tf.Tensor(shape=(None, 1, 45), dtype=float32)', 'tf.Tensor(shape=(None, 5), dtype=float32)')\n      • training=True\n      • mask=None\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_seq_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_nonseq_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Train data\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Total epochs for training\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_seq_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_nonseq_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Validation data\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_trial_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:339\u001b[0m, in \u001b[0;36mBaseTuner.on_trial_end\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_trial_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial):\n\u001b[1;32m    334\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called at the end of a trial.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m        trial: A `Trial` instance.\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/oracle.py:108\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m     LOCKS[oracle]\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    107\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m thread_name\n\u001b[0;32m--> 108\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_acquire:\n\u001b[1;32m    110\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/oracle.py:588\u001b[0m, in \u001b[0;36mOracle.end_trial\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry(trial):\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_order\u001b[38;5;241m.\u001b[39mappend(trial\u001b[38;5;241m.\u001b[39mtrial_id)\n\u001b[0;32m--> 588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_consecutive_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_trial(trial)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/oracle.py:545\u001b[0m, in \u001b[0;36mOracle._check_consecutive_failures\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    543\u001b[0m     consecutive_failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consecutive_failures \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials:\n\u001b[0;32m--> 545\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of consecutive failures exceeded the limit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    548\u001b[0m         \u001b[38;5;241m+\u001b[39m (trial\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    549\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/src/tuners/hyperband.py\", line 427, in run_trial\n    return super().run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/tmp/__autograph_generated_filent90i4eu.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Exception encountered when calling layer \"model\" (type Functional).\n    \n    Input 0 of layer \"lstm\" is incompatible with the layer: expected shape=(None, None, 1), found shape=(None, 1, 45)\n    \n    Call arguments received by layer \"model\" (type Functional):\n      • inputs=('tf.Tensor(shape=(None, 1, 45), dtype=float32)', 'tf.Tensor(shape=(None, 5), dtype=float32)')\n      • training=True\n      • mask=None\n\n"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    [X_seq_train, X_nonseq_train], y_train,  # Train data\n",
    "    epochs=50,  # Total epochs for training\n",
    "    validation_data=([X_seq_test, X_nonseq_test], y_test),  # Validation data\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186692a0-36af-4696-89cc-5ebb52ed2c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
